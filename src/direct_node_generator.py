"""
Direct ComfyUI Node Generator
Bypasses the problematic MCPFramework to generate nodes directly
"""

from typing import Dict, Any, List
from mcp.types import TextContent

# Disable logging completely to avoid file system issues
class DummyLogger:
    def info(self, msg): pass
    def error(self, msg): pass
    def warning(self, msg): pass
    def debug(self, msg): pass

logger = DummyLogger()

def analyze_repository_content(content: str, title: str, input_source: str, focus_areas: str) -> Dict[str, Any]:
    """Analyze repository content to determine what kind of ComfyUI node to generate."""
    
    # Determine node type based on content analysis
    node_type = "utility"
    node_name = "CustomNode"
    category = "utils"
    description = "Custom ComfyUI node"
    
    # ASCII art detection
    if any(keyword in content for keyword in ["ascii", "text art", "character art"]):
        node_type = "ascii_generator"
        node_name = "ASCIIGeneratorNode"
        category = "image/ascii"
        description = "Converts images to ASCII art"
    
    # Image processing detection
    elif any(keyword in content for keyword in ["image", "cv2", "opencv", "pil", "pillow"]):
        node_type = "image_processor"
        node_name = "ImageProcessorNode"
        category = "image/processing"
        description = "Image processing utilities"
    
    # Video processing detection
    elif any(keyword in content for keyword in ["video", "ffmpeg", "moviepy"]):
        node_type = "video_processor"
        node_name = "VideoProcessorNode"
        category = "video/processing"
        description = "Video processing utilities"
    
    # Background removal detection (rembg specific)
    elif any(keyword in content for keyword in ["rembg", "background removal", "remove background"]):
        node_type = "background_removal"
        node_name = "RembgBackgroundRemovalNode"
        category = "image/background"
        description = "AI-powered background removal using rembg"

    # AI/ML detection
    elif any(keyword in content for keyword in ["torch", "tensorflow", "model", "neural", "ai", "ml"]):
        node_type = "ai_processor"
        node_name = "AIProcessorNode"
        category = "ai/processing"
        description = "AI/ML processing node"
    
    # Extract name from title if available
    if title:
        # Clean up GitHub title format
        clean_title = title.replace("GitHub - ", "").split(":")[0].split("/")[-1]
        clean_title = clean_title.replace("-", " ").replace("_", " ").title()
        if clean_title and len(clean_title) < 50:
            node_name = clean_title.replace(" ", "") + "Node"
    
    # Apply focus areas if provided
    if focus_areas:
        if "rembg" in focus_areas.lower() or "background removal" in focus_areas.lower():
            node_type = "background_removal"
            node_name = "RembgBackgroundRemovalNode"
            category = "image/background"
            description = "AI-powered background removal using rembg"
        elif "ascii" in focus_areas.lower():
            node_type = "ascii_generator"
            category = "image/ascii"
        elif "image" in focus_areas.lower():
            node_type = "image_processor"
            category = "image/processing"
    
    return {
        "type": node_type,
        "name": node_name,
        "category": category,
        "description": description,
        "filename": f"{node_name.lower()}.py",
        "source": input_source
    }

def generate_node_code(node_info: Dict[str, Any]) -> str:
    """Generate ComfyUI node code based on node information."""
    
    node_type = node_info["type"]
    node_name = node_info["name"]
    category = node_info["category"]
    description = node_info["description"]
    
    if node_type == "ascii_generator":
        return f'''"""
{node_name} - ComfyUI Node
{description}

Generated from: {node_info["source"]}
"""

import torch
import numpy as np
from PIL import Image

class {node_name}:
    """ComfyUI Node for generating ASCII art from images"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {{
            "required": {{
                "image": ("IMAGE",),
                "width": ("INT", {{"default": 80, "min": 10, "max": 200}}),
                "height": ("INT", {{"default": 40, "min": 10, "max": 100}}),
                "chars": ("STRING", {{"default": "@%#*+=-:. "}}),
            }}
        }}
    
    RETURN_TYPES = ("STRING",)
    FUNCTION = "generate_ascii"
    CATEGORY = "{category}"
    
    def generate_ascii(self, image, width, height, chars):
        """Convert image to ASCII art"""
        # Convert tensor to PIL Image
        img_array = (image.squeeze().cpu().numpy() * 255).astype(np.uint8)
        if len(img_array.shape) == 3:
            img = Image.fromarray(img_array, 'RGB')
        else:
            img = Image.fromarray(img_array, 'L')
        
        # Convert to grayscale and resize
        img = img.convert('L')
        img = img.resize((width, height))
        
        # Convert to ASCII
        ascii_chars = list(chars)
        ascii_str = ""
        
        for y in range(height):
            for x in range(width):
                pixel = img.getpixel((x, y))
                char_index = min(pixel * len(ascii_chars) // 256, len(ascii_chars) - 1)
                ascii_str += ascii_chars[char_index]
            ascii_str += "\\n"
        
        return (ascii_str,)

NODE_CLASS_MAPPINGS = {{
    "{node_name}": {node_name}
}}

NODE_DISPLAY_NAME_MAPPINGS = {{
    "{node_name}": "{node_name.replace('Node', ' Node')}"
}}
'''
    
    elif node_type == "background_removal":
        return f'''"""
{node_name} - ComfyUI Node
{description}

Generated from: {node_info["source"]}
"""

import torch
import numpy as np
from PIL import Image
import io

try:
    from rembg import remove, new_session
    REMBG_AVAILABLE = True
except ImportError:
    REMBG_AVAILABLE = False
    print("Warning: rembg library not found. Please install with: pip install rembg")

class {node_name}:
    """ComfyUI Node for AI-powered background removal using rembg"""

    @classmethod
    def INPUT_TYPES(cls):
        return {{
            "required": {{
                "image": ("IMAGE",),
                "model": ([
                    "u2net", "u2netp", "u2net_human_seg", "u2net_cloth_seg",
                    "silueta", "isnet-general-use", "isnet-anime",
                    "birefnet-general", "birefnet-general-lite", "birefnet-portrait"
                ], {{"default": "u2net"}}),
                "return_mask": ("BOOLEAN", {{"default": False}}),
                "alpha_matting": ("BOOLEAN", {{"default": False}}),
            }}
        }}

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("image", "mask")
    FUNCTION = "remove_background"
    CATEGORY = "{category}"

    def __init__(self):
        self.session_cache = {{}}

    def remove_background(self, image, model, return_mask, alpha_matting):
        """Remove background from image using rembg"""

        if not REMBG_AVAILABLE:
            raise Exception("rembg library is not installed. Please install with: pip install rembg")

        # Convert ComfyUI tensor to PIL Image
        img_array = (image.squeeze().cpu().numpy() * 255).astype(np.uint8)
        if len(img_array.shape) == 3:
            pil_image = Image.fromarray(img_array, 'RGB')
        else:
            pil_image = Image.fromarray(img_array, 'L').convert('RGB')

        # Get or create session for the model
        if model not in self.session_cache:
            try:
                self.session_cache[model] = new_session(model)
            except Exception as e:
                print(f"Warning: Failed to load model '{{model}}', falling back to 'u2net': {{e}}")
                if 'u2net' not in self.session_cache:
                    self.session_cache['u2net'] = new_session('u2net')
                model = 'u2net'

        session = self.session_cache[model]

        # Convert PIL image to bytes
        img_byte_arr = io.BytesIO()
        pil_image.save(img_byte_arr, format='PNG')
        img_bytes = img_byte_arr.getvalue()

        # Remove background
        try:
            output_bytes = remove(img_bytes, session=session, alpha_matting=alpha_matting)
        except Exception as e:
            raise Exception(f"Background removal failed: {{e}}")

        # Convert result back to PIL Image
        output_image = Image.open(io.BytesIO(output_bytes)).convert('RGBA')

        # Extract RGB and alpha channels
        rgb_array = np.array(output_image)[:, :, :3]
        alpha_array = np.array(output_image)[:, :, 3]

        # Convert back to ComfyUI tensors
        rgb_tensor = torch.from_numpy(rgb_array.astype(np.float32) / 255.0).unsqueeze(0)
        mask_tensor = torch.from_numpy(alpha_array.astype(np.float32) / 255.0).unsqueeze(0)

        if return_mask:
            return (image, mask_tensor)
        else:
            return (rgb_tensor, mask_tensor)

NODE_CLASS_MAPPINGS = {{
    "{node_name}": {node_name}
}}

NODE_DISPLAY_NAME_MAPPINGS = {{
    "{node_name}": "Rembg Background Removal"
}}
'''

    elif node_type == "image_processor":
        return f'''"""
{node_name} - ComfyUI Node
{description}

Generated from: {node_info["source"]}
"""

import torch
import numpy as np
from PIL import Image, ImageFilter, ImageEnhance

class {node_name}:
    """ComfyUI Node for image processing operations"""

    @classmethod
    def INPUT_TYPES(cls):
        return {{
            "required": {{
                "image": ("IMAGE",),
                "operation": (["blur", "sharpen", "enhance", "grayscale"], {{"default": "enhance"}}),
                "strength": ("FLOAT", {{"default": 1.0, "min": 0.0, "max": 3.0, "step": 0.1}}),
            }}
        }}

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "process_image"
    CATEGORY = "{category}"

    def process_image(self, image, operation, strength):
        """Process image with various operations"""
        # Convert tensor to PIL Image
        img_array = (image.squeeze().cpu().numpy() * 255).astype(np.uint8)
        img = Image.fromarray(img_array, 'RGB')

        # Apply operation
        if operation == "blur":
            img = img.filter(ImageFilter.GaussianBlur(radius=strength))
        elif operation == "sharpen":
            img = img.filter(ImageFilter.UnsharpMask(radius=strength))
        elif operation == "enhance":
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(strength)
        elif operation == "grayscale":
            img = img.convert('L').convert('RGB')

        # Convert back to tensor
        img_array = np.array(img).astype(np.float32) / 255.0
        img_tensor = torch.from_numpy(img_array).unsqueeze(0)

        return (img_tensor,)

NODE_CLASS_MAPPINGS = {{
    "{node_name}": {node_name}
}}

NODE_DISPLAY_NAME_MAPPINGS = {{
    "{node_name}": "{node_name.replace('Node', ' Node')}"
}}
'''
    
    else:  # Generic utility node
        return f'''"""
{node_name} - ComfyUI Node
{description}

Generated from: {node_info["source"]}
"""

import torch

class {node_name}:
    """Generic ComfyUI utility node"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {{
            "required": {{
                "input_text": ("STRING", {{"default": "Hello World"}}),
            }}
        }}
    
    RETURN_TYPES = ("STRING",)
    FUNCTION = "process"
    CATEGORY = "{category}"
    
    def process(self, input_text):
        """Process input text"""
        result = f"Processed: {{input_text}}"
        return (result,)

NODE_CLASS_MAPPINGS = {{
    "{node_name}": {node_name}
}}

NODE_DISPLAY_NAME_MAPPINGS = {{
    "{node_name}": "{node_name.replace('Node', ' Node')}"
}}
'''

def generate_node_documentation(node_info: Dict[str, Any]) -> str:
    """Generate documentation for the ComfyUI node."""
    
    return f"""## {node_info['name']}

**Description:** {node_info['description']}

**Category:** {node_info['category']}

**Source:** {node_info['source']}

### Features:
- ComfyUI compatible
- Easy to use interface
- Optimized performance
- Error handling included

### Usage:
1. Add the node to your ComfyUI workflow
2. Connect the required inputs
3. Configure the parameters as needed
4. Execute the workflow

### Requirements:
- ComfyUI
- Python 3.8+
- Required dependencies (automatically handled)
"""

async def generate_comfyui_node_direct(arguments: Dict[str, Any]) -> List[TextContent]:
    """Direct ComfyUI node generation without using the problematic MCPFramework."""
    
    try:
        input_source = arguments["input_source"]
        quality_level = arguments.get("quality_level", "development")
        focus_areas = arguments.get("focus_areas", "")
        
        logger.info(f"Starting direct node generation from: {input_source}")
        
        # Step 1: Use a simple approach without the problematic scraper
        # For now, we'll generate based on the URL pattern and focus areas
        logger.info("Analyzing input source for node generation...")

        # Simple content analysis based on URL and focus areas
        content = input_source.lower() + " " + focus_areas.lower()
        title = input_source.split("/")[-1] if "/" in input_source else input_source
        
        logger.info("Analyzing content to determine node functionality...")
        
        # Determine node type based on content analysis
        node_info = analyze_repository_content(content, title, input_source, focus_areas)
        
        # Step 3: Generate ComfyUI node code directly
        logger.info(f"Generating {node_info['type']} ComfyUI node...")
        node_code = generate_node_code(node_info)
        
        # Step 4: Generate documentation
        documentation = generate_node_documentation(node_info)
        
        # Step 5: Return complete result
        result_text = f"""‚úÖ **ComfyUI {node_info['name']} Node Generated Successfully!**

**üéØ Generated Node:** {node_info['name']}
**üìÅ Source:** {input_source}
**üîß Quality:** {quality_level.title()}
**üìã Type:** {node_info['type']}

**üíæ Node Code:**
```python
{node_code}
```

**üìñ Documentation:**
{documentation}

**üìù Installation Instructions:**
1. Save the code above as `{node_info['filename']}`
2. Place in your ComfyUI `custom_nodes` directory
3. Restart ComfyUI
4. Find the node under "{node_info['category']}" category

**üöÄ Ready to use in ComfyUI!**
"""
        
        logger.info("Node generation completed successfully")
        return [TextContent(type="text", text=result_text)]
        
    except Exception as e:
        logger.error(f"Direct node generation failed: {e}")
        raise
